{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebf629e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12886c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbcc7f",
   "metadata": {},
   "source": [
    "### 1a. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8a65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modelingdf.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0566c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>PhysicalHealthDays</th>\n",
       "      <th>MentalHealthDays</th>\n",
       "      <th>LastCheckup</th>\n",
       "      <th>ExerciseLast30days</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>HadAngina</th>\n",
       "      <th>HadStroke</th>\n",
       "      <th>...</th>\n",
       "      <th>EcigUsage</th>\n",
       "      <th>HadCovid</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>RaceEthnicityGroup</th>\n",
       "      <th>AgeGroup5yrs</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DrinkOccasionsPerDay</th>\n",
       "      <th>Smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.60</td>\n",
       "      <td>68.04</td>\n",
       "      <td>26.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.57</td>\n",
       "      <td>63.50</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.65</td>\n",
       "      <td>63.50</td>\n",
       "      <td>23.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.57</td>\n",
       "      <td>53.98</td>\n",
       "      <td>21.77</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.80</td>\n",
       "      <td>84.82</td>\n",
       "      <td>26.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Sex  GeneralHealth  PhysicalHealthDays  MentalHealthDays  \\\n",
       "1      1    0              5                 0.0               0.0   \n",
       "2      1    0              4                 2.0               3.0   \n",
       "3      1    0              5                 0.0               0.0   \n",
       "4      1    0              2                 2.0               0.0   \n",
       "5      1    1              1                 1.0               0.0   \n",
       "\n",
       "   LastCheckup  ExerciseLast30days  SleepTime  HadAngina  HadStroke  ...  \\\n",
       "1            0                 0.0        6.0        0.0        0.0  ...   \n",
       "2            1                 1.0        5.0        0.0        0.0  ...   \n",
       "3            1                 1.0        7.0        0.0        0.0  ...   \n",
       "4            1                 1.0        9.0        0.0        0.0  ...   \n",
       "5            1                 0.0        7.0        0.0        1.0  ...   \n",
       "\n",
       "   EcigUsage  HadCovid  HeartDisease  RaceEthnicityGroup  AgeGroup5yrs  \\\n",
       "1        0.0       0.0             0                   0            12   \n",
       "2        0.0       1.0             0                   0             7   \n",
       "3        0.0       0.0             0                   0             9   \n",
       "4        0.0       0.0             0                   0             4   \n",
       "5        0.0       0.0             1                   0            12   \n",
       "\n",
       "   Height  Weight    BMI  DrinkOccasionsPerDay  Smoked  \n",
       "1    1.60   68.04  26.57                   0.0     0.0  \n",
       "2    1.57   63.50  25.61                   0.0     0.0  \n",
       "3    1.65   63.50  23.30                   0.0     1.0  \n",
       "4    1.57   53.98  21.77                  10.0     0.0  \n",
       "5    1.80   84.82  26.08                   0.0     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38cdf365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356169 entries, 1 to 445131\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   State                 356169 non-null  int64  \n",
      " 1   Sex                   356169 non-null  int64  \n",
      " 2   GeneralHealth         356169 non-null  int64  \n",
      " 3   PhysicalHealthDays    356169 non-null  float64\n",
      " 4   MentalHealthDays      356169 non-null  float64\n",
      " 5   LastCheckup           356169 non-null  int64  \n",
      " 6   ExerciseLast30days    355543 non-null  float64\n",
      " 7   SleepTime             356169 non-null  float64\n",
      " 8   HadAngina             355160 non-null  float64\n",
      " 9   HadStroke             355376 non-null  float64\n",
      " 10  HadCOPD               354858 non-null  float64\n",
      " 11  HadKidneyDisease      355028 non-null  float64\n",
      " 12  HadArthritis          354457 non-null  float64\n",
      " 13  HadDiabetes           355656 non-null  float64\n",
      " 14  Deaf                  355111 non-null  float64\n",
      " 15  DifficultyWalking     355142 non-null  float64\n",
      " 16  EcigUsage             354957 non-null  float64\n",
      " 17  HadCovid              355307 non-null  float64\n",
      " 18  HeartDisease          356169 non-null  int64  \n",
      " 19  RaceEthnicityGroup    356169 non-null  int64  \n",
      " 20  AgeGroup5yrs          356169 non-null  int64  \n",
      " 21  Height                356169 non-null  float64\n",
      " 22  Weight                356169 non-null  float64\n",
      " 23  BMI                   356169 non-null  float64\n",
      " 24  DrinkOccasionsPerDay  356169 non-null  float64\n",
      " 25  Smoked                353900 non-null  float64\n",
      "dtypes: float64(19), int64(7)\n",
      "memory usage: 73.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41592fc",
   "metadata": {},
   "source": [
    "## 2. Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c970e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features + Target datasets\n",
    "X = df.drop(columns =['HeartDisease'], axis = 1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cedb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdd94c",
   "metadata": {},
   "source": [
    "## Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5f095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_2_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    beta = 2\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae44d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'acc': acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'f1': f1,\n",
    "        'beta_2' :beta_2,\n",
    "        'auc': auc,\n",
    "        'cm': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726a207",
   "metadata": {},
   "source": [
    "# Testing for scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cabc9",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef3b9a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy = 0.9686, Recall = 0.8364, F1 Score = 0.8014, Beta=2 Score = 0.7195, Precision = 0.9891, ROC AUC Score = 0.9285\n",
      "Confusion Matrix:\n",
      "[[64474    50]\n",
      " [ 2190  4520]]\n",
      "\n",
      "MinMaxScaler: Accuracy = 0.9684, Recall = 0.8364, F1 Score = 0.8006, Beta=2 Score = 0.7194, Precision = 0.9863, ROC AUC Score = 0.9287\n",
      "Confusion Matrix:\n",
      "[[64461    63]\n",
      " [ 2189  4521]]\n",
      "\n",
      "RobustScaler: Accuracy = 0.9689, Recall = 0.8362, F1 Score = 0.8030, Beta=2 Score = 0.7193, Precision = 0.9962, ROC AUC Score = 0.9271\n",
      "Confusion Matrix:\n",
      "[[64507    17]\n",
      " [ 2197  4513]]\n",
      "\n",
      "MaxAbsScaler: Accuracy = 0.9684, Recall = 0.8367, F1 Score = 0.8009, Beta=2 Score = 0.7200, Precision = 0.9856, ROC AUC Score = 0.9292\n",
      "Confusion Matrix:\n",
      "[[64458    66]\n",
      " [ 2184  4526]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_rf = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # KNN classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_rf[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_rf.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d63ab",
   "metadata": {},
   "source": [
    "best scaler for random forest is MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277f09e",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1568384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy = 0.9125, Recall = 0.8594, F1 Score = 0.6309, Beta=2 Score = 0.7196, Precision = 0.5234, ROC AUC Score = 0.9371\n",
      "Confusion Matrix:\n",
      "[[59672  4852]\n",
      " [ 1382  5328]]\n",
      "\n",
      "MinMaxScaler: Accuracy = 0.9146, Recall = 0.8596, F1 Score = 0.6358, Beta=2 Score = 0.7211, Precision = 0.5312, ROC AUC Score = 0.9369\n",
      "Confusion Matrix:\n",
      "[[59835  4689]\n",
      " [ 1397  5313]]\n",
      "\n",
      "RobustScaler: Accuracy = 0.9351, Recall = 0.8559, F1 Score = 0.6877, Beta=2 Score = 0.7284, Precision = 0.6292, ROC AUC Score = 0.9355\n",
      "Confusion Matrix:\n",
      "[[61525  2999]\n",
      " [ 1622  5088]]\n",
      "\n",
      "MaxAbsScaler: Accuracy = 0.9141, Recall = 0.8591, F1 Score = 0.6345, Beta=2 Score = 0.7201, Precision = 0.5296, ROC AUC Score = 0.9369\n",
      "Confusion Matrix:\n",
      "[[59808  4716]\n",
      " [ 1401  5309]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_log = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', LogisticRegression(random_state=42))  # KNN classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_log[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_log.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40d084",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION BEST SCALER IS ROBUST SCALER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc58028",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72cb1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy = 0.9688, Recall = 0.8365, F1 Score = 0.8026, Beta=2 Score = 0.7198, Precision = 0.9930, ROC AUC Score = 0.9370\n",
      "Confusion Matrix:\n",
      "[[64492    32]\n",
      " [ 2191  4519]]\n",
      "\n",
      "MinMaxScaler: Accuracy = 0.9688, Recall = 0.8368, F1 Score = 0.8030, Beta=2 Score = 0.7203, Precision = 0.9930, ROC AUC Score = 0.9373\n",
      "Confusion Matrix:\n",
      "[[64492    32]\n",
      " [ 2187  4523]]\n",
      "\n",
      "RobustScaler: Accuracy = 0.9690, Recall = 0.8365, F1 Score = 0.8035, Beta=2 Score = 0.7199, Precision = 0.9963, ROC AUC Score = 0.9368\n",
      "Confusion Matrix:\n",
      "[[64507    17]\n",
      " [ 2193  4517]]\n",
      "\n",
      "MaxAbsScaler: Accuracy = 0.9688, Recall = 0.8365, F1 Score = 0.8029, Beta=2 Score = 0.7199, Precision = 0.9938, ROC AUC Score = 0.9377\n",
      "Confusion Matrix:\n",
      "[[64496    28]\n",
      " [ 2191  4519]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_xg = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', XGBClassifier(eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_xg[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_xg.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb43cb7",
   "metadata": {},
   "source": [
    "best scaler for XGBoost is MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d792194",
   "metadata": {},
   "source": [
    "# Hyperparater tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6ee64",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d335568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "Best Recall Score: 0.7223\n",
      "Test Recall: 0.7201\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     64524\n",
      "           1       0.77      0.72      0.74      6710\n",
      "\n",
      "    accuracy                           0.95     71234\n",
      "   macro avg       0.87      0.85      0.86     71234\n",
      "weighted avg       0.95      0.95      0.95     71234\n",
      "\n",
      "f1_score: 0.7424708051628764\n",
      "beta_2: 0.7288963977553853\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100],  # Number of trees in the forest\n",
    "    'classifier__max_depth': [10],  # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    #'classifier__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    #'classifier__bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2  # Print progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Recall Score: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f0d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Best Recall Score: 0.7623\n",
      "Test Recall: 0.7574\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     64524\n",
      "           1       0.63      0.76      0.69      6710\n",
      "\n",
      "    accuracy                           0.94     71234\n",
      "   macro avg       0.80      0.86      0.83     71234\n",
      "weighted avg       0.94      0.94      0.94     71234\n",
      "\n",
      "f1_score: 0.6887578776174019\n",
      "beta_2: 0.7283515349557141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [1],               # Regularization strength\n",
    "    'classifier__penalty': [ 'l1'],    # Type of regularization\n",
    "    'classifier__solver': [ 'saga']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', RobustScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', LogisticRegression(random_state=42))  # Logistic Regression classifier\n",
    "])\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2  # Print progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Recall Score: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_log_reg_model = grid_search.best_estimator_\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a9034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=30. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:09:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {}\n",
      "Best Cross-Validation Recall: 0.7022\n",
      "Test Recall: 0.7001\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     64524\n",
      "           1       0.85      0.70      0.77      6710\n",
      "\n",
      "    accuracy                           0.96     71234\n",
      "   macro avg       0.91      0.84      0.87     71234\n",
      "weighted avg       0.96      0.96      0.96     71234\n",
      "\n",
      "f1_score: 0.7670204081632653\n",
      "beta_2: 0.7254478072884495\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Define the parameter distribution\n",
    "param_dist = { \n",
    "    #'classifier__n_estimators': np.arange(50, 201, 50),           # Number of boosting rounds, 200\n",
    "    #'classifier__learning_rate': np.logspace(-3, -1, 5),          # Learning rate, 0.1\n",
    "    #'classifier__max_depth': np.arange(3, 10, 1),                 # Maximum depth of a tree, 9 \n",
    "    #'classifier__subsample': np.linspace(0.6, 1.0, 5),            # Subsample ratio of the training instance,0.6\n",
    "    #'classifier__colsample_bytree': np.linspace(0.6, 1.0, 5),     # Subsample ratio of columns when constructing each tree, 0.6\n",
    "    #'classifier__gamma': np.linspace(0, 0.4, 5)                   # Minimum loss reduction required to make a further partition,0.1\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', MaxAbsScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', XGBClassifier(n_estimators =200,learning_rate = 0.01,max_depth = 6, subsample=0.7,colsample_bytree=0.6\n",
    "                                 ,use_label_encoder=False,gamma= 0.1, eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "])\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Number of parameter settings to sample\n",
    "    scoring='recall',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,  # Print progress\n",
    "    random_state=42  # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation Recall: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = random_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b597a28",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943d0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = evaluate_model(best_knn_model, X_test, y_test)\n",
    "log_reg_results = evaluate_model(best_log_reg_model, X_test, y_test)\n",
    "xgb_results = evaluate_model(best_xgb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1676545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9529438189628548\n",
      "Precision: 0.7662543609261021\n",
      "Recall: 0.7201192250372578\n",
      "F1 Score: 0.7424708051628764\n",
      "beta_2 0.7288963977553853\n",
      "Area Under Curve: 0.9357186390100942\n",
      "Confusion Matrix:\n",
      " [[63050  1474]\n",
      " [ 1878  4832]]\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print('Accuracy:', knn_results['acc'])\n",
    "print('Precision:', knn_results['prec'])\n",
    "print('Recall:', knn_results['rec'])\n",
    "print('F1 Score:', knn_results['f1'])\n",
    "print('beta_2',knn_results['beta_2'])\n",
    "print('Area Under Curve:', knn_results['auc'])\n",
    "print('Confusion Matrix:\\n', knn_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d4d6a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9355223629165847\n",
      "Precision: 0.6315397042376041\n",
      "Recall: 0.7573770491803279\n",
      "F1 Score: 0.6887578776174019\n",
      "beta_2 0.7283515349557141\n",
      "Area Under Curve: 0.9354267883640104\n",
      "Confusion Matrix:\n",
      " [[61559  2965]\n",
      " [ 1628  5082]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', log_reg_results['acc'])\n",
    "print('Precision:', log_reg_results['prec'])\n",
    "print('Recall:', log_reg_results['rec'])\n",
    "print('F1 Score:', log_reg_results['f1'])\n",
    "print('beta_2',log_reg_results['beta_2'])\n",
    "print('Area Under Curve:', log_reg_results['auc'])\n",
    "print('Confusion Matrix:\\n', log_reg_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4fb273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599348625656288\n",
      "Precision: 0.848014440433213\n",
      "Recall: 0.7001490312965722\n",
      "F1 Score: 0.7670204081632653\n",
      "beta_2 0.7254478072884495\n",
      "Area Under Curve: 0.9343119038136067\n",
      "Confusion Matrix:\n",
      " [[63682   842]\n",
      " [ 2012  4698]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', xgb_results['acc'])\n",
    "print('Precision:', xgb_results['prec'])\n",
    "print('Recall:', xgb_results['rec'])\n",
    "print('F1 Score:', xgb_results['f1'])\n",
    "print('beta_2',xgb_results['beta_2'])\n",
    "print('Area Under Curve:', xgb_results['auc'])\n",
    "print('Confusion Matrix:\\n', xgb_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ce330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
